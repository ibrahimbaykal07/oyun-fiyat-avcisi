import json
import time
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager # KRÄ°TÄ°K EKLENTÄ°
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- AYARLAR ---
FILE_NAME = "subscriptions.json"

def setup_driver():
    """GitHub Actions Uyumlu SÃ¼rÃ¼cÃ¼ AyarlarÄ±"""
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument("--blink-settings=imagesEnabled=false")
    chrome_options.page_load_strategy = 'eager'
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # OTOMATÄ°K SÃœRÃœCÃœ KURULUMU (HATA Ã‡Ã–ZÃœCÃœ)
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)

def clean_name(name):
    name = re.sub(r'\[.*?\]', '', name)
    name = re.sub(r'\(.*?\)', '', name)
    return name.strip()

def scrape_specific_condition(url, target_col_name, match_string, is_ubisoft=False):
    print(f"   ğŸš€ BaÄŸlanÄ±lÄ±yor -> {url}")
    games = []
    driver = None
    
    try:
        driver = setup_driver()
        driver.set_page_load_timeout(60) # SÃ¼reyi artÄ±rdÄ±m
        
        try:
            driver.get(url)
        except:
            print("   âš ï¸ Sayfa yÃ¼kleme zaman aÅŸÄ±mÄ± (devam ediliyor)...")
            driver.execute_script("window.stop();")

        # Tabloyu bekle
        try:
            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, "wikitable")))
        except:
            print("   âš ï¸ Tablo bulunamadÄ±, sayfa yapÄ±sÄ± farklÄ± olabilir.")

        tables = driver.find_elements(By.CLASS_NAME, "wikitable")
        print(f"   â„¹ï¸ {len(tables)} tablo taraniyor...")

        for table in tables:
            try:
                # BaÅŸlÄ±klarÄ± analiz et
                headers = table.find_elements(By.TAG_NAME, "th")
                col_map = {}
                for i, h in enumerate(headers):
                    col_map[i] = h.text.strip().lower()
                
                target_idx = -1
                
                if is_ubisoft:
                    target_idx = 0 
                else:
                    for idx, text in col_map.items():
                        if target_col_name.lower() in text:
                            target_idx = idx
                            break
                
                if target_idx == -1: continue 

                rows = table.find_elements(By.TAG_NAME, "tr")
                for row in rows[1:]:
                    cells = row.find_elements(By.TAG_NAME, "td")
                    
                    # GÃ¼venli hÃ¼cre okuma
                    # PCGamingWiki'de bazen ilk sÃ¼tun TH olur, bazen TD.
                    # SatÄ±rÄ±n tamamÄ±ndan isme ulaÅŸmaya Ã§alÄ±ÅŸalÄ±m.
                    try:
                        # SatÄ±rÄ±n ilk hÃ¼cresi (oyun adÄ±)
                        first_cell = row.find_elements(By.XPATH, "./*[1]")[0]
                        name = clean_name(first_cell.text)
                    except: continue

                    if not name: continue

                    if is_ubisoft:
                        games.append(name)
                        continue

                    # DiÄŸerleri iÃ§in koÅŸul kontrolÃ¼
                    # target_idx'e denk gelen hÃ¼creyi bulmaya Ã§alÄ±ÅŸ (Offset olabilir)
                    # En garantisi: SatÄ±rdaki tÃ¼m hÃ¼creleri (td+th) alÄ±p index'e bakmak
                    all_cells = row.find_elements(By.XPATH, "./*")
                    
                    if len(all_cells) > target_idx:
                        target_cell = all_cells[target_idx]
                        cell_html = target_cell.get_attribute('innerHTML')
                        
                        # KULLANICININ VERDÄ°ÄÄ° KOD KONTROLÃœ
                        if match_string in cell_html:
                            games.append(name)

            except Exception as inner_e:
                # Tek bir tabloda hata olursa diÄŸerine geÃ§
                continue 

    except Exception as e:
        print(f"   âŒ Genel Hata: {e}")
    finally:
        if driver: driver.quit()
        
    unique = sorted(list(set(games)))
    print(f"   âœ… '{target_col_name}' iÃ§in {len(unique)} oyun bulundu.")
    return unique

def load_existing_data():
    if os.path.exists(FILE_NAME):
        try:
            with open(FILE_NAME, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: pass
    return {"Game Pass": [], "EA Play": [], "EA Play Pro": [], "Ubisoft+": []}

def main():
    print("ğŸ¤– --- ROBOT BAÅLATILIYOR (V8 - DRIVER MANAGER) ---")
    
    # Hata olursa eski veriyi korumak iÃ§in yÃ¼kle
    final_data = load_existing_data()
    
    # 1. GAME PASS
    print("\n1ï¸âƒ£ Game Pass...")
    gp = scrape_specific_condition(
        "https://www.pcgamingwiki.com/wiki/List_of_PC_Game_Pass_games", 
        "game pass for pc", 
        "tickcross-true"
    )
    if len(gp) > 10: final_data["Game Pass"] = gp

    # 2. EA PLAY (BASIC)
    print("\n2ï¸âƒ£ EA Play...")
    ea_play = scrape_specific_condition(
        "https://www.pcgamingwiki.com/wiki/List_of_EA_Play_games", 
        "ea app", 
        "store-origin"
    )
    if len(ea_play) > 5: final_data["EA Play"] = ea_play

    # 3. EA PLAY PRO
    print("\n3ï¸âƒ£ EA Play Pro...")
    ea_pro = scrape_specific_condition(
        "https://www.pcgamingwiki.com/wiki/List_of_EA_Play_games", 
        "ea play pro", 
        "store-origin"
    )
    # Manuel destek (FC 26 vb. henÃ¼z listede yoksa ekle)
    manual_pro = ["FC 26", "FC 25", "F1 24", "Madden NFL 25", "Star Wars Jedi: Survivor"]
    
    if len(ea_pro) > 2:
        final_data["EA Play Pro"] = list(set(ea_pro + manual_pro))
    else:
        # Ã‡ekemediysek eskiyi koru + manueli ekle
        existing = final_data.get("EA Play Pro", [])
        final_data["EA Play Pro"] = list(set(existing + manual_pro))

    # 4. UBISOFT+
    print("\n4ï¸âƒ£ Ubisoft+...")
    ubi = scrape_specific_condition(
        "https://www.pcgamingwiki.com/wiki/List_of_Ubisoft%2B_games", 
        "game", 
        "", 
        is_ubisoft=True
    )
    if len(ubi) > 10: final_data["Ubisoft+"] = ubi

    # Zaman DamgasÄ± (GitHub'Ä± tetiklemek iÃ§in)
    final_data["_meta"] = {
        "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    with open(FILE_NAME, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=4)
        
    print("\nğŸ‰ Ä°ÅŸlem TamamlandÄ±.")

if __name__ == "__main__":
    main()
